<!DOCTYPE html>
<html>
<title>Henry's personal site</title>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="../../w3.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<style>
body, h1,h2,h3,h4,h5,h6 {font-family: "Montserrat", sans-serif}
.w3-row-padding img {margin-bottom: 12px}
/* Set the width of the sidenav to 120px */
.w3-sidenav {width: 120px;background: #222;}
/* Add a left margin to the "page content" that matches the width of the sidenav (120px) */
#main {margin-left: 120px}
/* Remove margins from "page content" on small screens */
@media only screen and (max-width: 600px) {#main {margin-left: 0}}
</style>
<body class="w3-black">
    
<nav class="w3-sidenav w3-center w3-small w3-hide-small">
  <a class="w3-padding-large w3-hover-black" href="../../index.html">
    <i class="fa fa-home w3-xxlarge"></i>
    <p>HOME</p>
  </a>
  <a class="w3-padding-large w3-hover-black" href="../../about.html">
    <i class="fa fa-user w3-xxlarge"></i>
    <p>ABOUT</p>
  </a>
  <a class="w3-padding-large w3-black" href="../../projects.html">
    <img src="../../elements/sidebar/code-optimization-xxl.png" style="width:55% !important" alt="hi" class="inline"/>
    <p>PROJECTS</p>
  </a>
<!--
  <a class="w3-padding-large w3-hover-black" href="../../index.html">
    <i class="fa fa-envelope w3-xxlarge"></i>
    <p>CONTACT</p>
  </a>
-->
</nav>
<!-- Navbar on small screens (Hidden on medium and large screens) -->
<div class="w3-top w3-hide-large w3-hide-medium" id="myNavbar">
  <ul class="w3-navbar w3-black w3-opacity w3-hover-opacity-off w3-center w3-small">
    <li class="w3-left" style="width:25% !important"><a href="../../index.html">HOME</a></li>
    <li class="w3-left" style="width:25% !important"><a href="../../about.html">ABOUT</a></li>
    <li class="w3-left" style="width:25% !important"><a href="../../projects.html">PROJECTS</a></li>
<!--
    <li class="w3-left" style="width:25% !important"><a href="index.html">CONTACT</a></li>
-->
  </ul>
</div>
    
<div class="w3-padding-large" id="main">
    
    
<!-- Blog entries -->
<div class="w3-col l18 s12">


  <!-- Blog entry -->
  <div class="w3-card-4 w3-margin w3-white">
      
    <div class="w3-container w3-padding-8">
      <h3><b>PathFire: A 3D Raytracer</b></h3>
      <h5>A rendering engine built from the ground up in C++, <span class="w3-opacity">June, 2017</span></h5>
    </div>

    <div class="w3-container">
        <p>
            This project started when I was watching the Netflix series, Stranger Things. VFX has always been a side hobby of mine so when I saw the 3D creature in the show, I was captured because it looked so cool. At the time it had been awhile since I did some VFX, so this kind of sparked my interest again. Over the next couple days (between the stresses of my classes), I would spare a little brain power to get reacquainted with <a href="https://www.blender.org/">Blender 3D</a>: my favorite 3D modeling software that I've been using since I was a little kid.
        </p>
        
        <p>
             Modeling software is always changing, but one thing that's stayed constant is rendering times. They're long. VERY long. Take Toy Story 3 for example: each frame of the film took, on average, 7 hours to render. Sometimes up to 39. That's a long time! Especially considering there's 24 frames per second of film. Of course, they have render farms with tons of machines to split up the workload so it doesn't take tens of years. 
        </p>
        
        <p>
            Obviously my VFX work isn't going to be so complex that it takes 7 hours per frame to render, but it's not hard to get up to 30 minutes. This can get extremely frustrating when trying to make small changes because you can't really tell what your work is going to look like until the frame renders. And not only that, but my computer gets so hot while rendering that I could burn myself. Which isn't good. So this is where I started to wonder to myself, "could I run my pieces through a render farm somewhere so I don't have to deal with this?" Turns out there's a lot of options for offsite rendering, but there's a problem: it costs money. Nope! Not on an option on my college student budget.
        </p>
        
        <p>
            When I started thinking about my other options, it hit me: there's tons of computers on my campus that are set up for remote log in! Why not distribute my rendering across those? Blender 3D comes with a few plugins to help with distributed rendering, but that quickly became a mess because it was hard to keep track of the virtual machine instances. 
        </p>
        
        <p>
            Since it was pretty clear that using pre-made tools wasn't feasible for my setup, the next logical step was to see if I could break apart the software to twist it into working. Luckily Blender 3D is open source so all the source code is available to the public. Unfortunately, they have very little documentation. I poured many hours into dissecting the renderer to see if I could understand how to implement it into my own distributed rendering system. It came so close to working, but there was always a couple parts that weren't working and once those were fixed, it spawned even more issues. Frustrated, I gave up. Then took it up again, and gave up again.
        </p>
        
        <p>
            After a few months of not working on this project, I was researching computer graphics out of curiosity and I regained interest. "Why not build my own renderer?" I thought to myself. It would be a daunting task, but the combination of art and computer science seemed like the perfect project for me. 
        </p>
        
        <p>
            Even just finding a starting point took me quite some time because I had very little knowledge of computer graphics. I started simple -- figuring out how to put a colored pixel on the screen. Then, I moved on to perspectives, projections, rays, geometry representations, surface normals and, finally, raytracing.  
        </p>
        
        <p>
            Once I started getting into the math side of the physics light-transport equations and vector math, I started to struggle. I had not yet taken multivariable calculus or linear algebra, which is what a lot of computer graphics relies upon. Those courses weren't too far ahead in my college career, but I wasn't about to just wait until then. So, I set aside the time to learn the necessary topics. One thing I've learned about this project is that it has roots in a wide spread of areas. It turned out to be a good thing that I went ahead and learned the mathematics behind it because it helped me understand the courses I was taking on a deeper level. I was able to visualize in my head these beautiful properties that would've likely given me trouble otherwise.
        </p>
        
        <p>
            Getting back to the renderer, my first test was to make a surface normal visualizer. At this point I had created an OBJ (file format for 3D models) reader, a basic ray tracer, and an image routine. Below you can see the result. The input file is nothing more than a list of triangles. The colors you see are based off of what direction the surface normal is pointing in.
        </p>
        
        <div class="w3-center">
        <img class="w3-image" src="images/arrow.png" width="700" alt="Normal Visualization"/>
        </div>
        
        <p>
            Now I was getting somewhere! My next step was to turn my ray tracer into a path tracer. The difference between the two is a ray tracer can only compute direct lighting, where's a path tracer lets the rays bounce around the scene as they would in the physical world. Hence, why it's a photorealistic rendering. It's a rather simple technique, but it allows such incredible renderings. Below is the equation used to calculate path tracing.
        </p>
        
        <div class="w3-center">
        <img class="w3-image" src="images/lte.jpg" width="400" alt="Light Transport Equation"/>
        </div>
        
        <p>
            It's a simple idea, but the fun comes when you start using different techniques to evaluate the integral. The most common is Monte Carlo integration, which is the method I chose. In short, it's essentially throwing mathematical darts towards a dart board. And to speed things up, I use importance sampling (steering the darts towards the right spot, but ensuring the answer remains unbiased by calculating the probability of said direction). These darts do create noise, which you'll see below, but with enough samples the image will be clean. There's other techniques to speed things up, but that usually leads to the renderer being biased, making it no longer physically accurate. 
        </p>
        
        <p>
            After many sleepless nights and frustrations, it started coming alive. I was absolutely astonished when I saw a side-by-side comparison of my renderer and Blender's. The pop-up window on the right is mine, and the left is Blender's.
        </p>
        
        <div class="w3-center">
        <img class="w3-image" src="images/example.png" width="700" alt="Light Transport Equation"/>
        </div>
        
        <p>
            And another with a glossy material. Left: mine, Right: Blender
        </p>
        
        <div class="w3-center">
        <img class="w3-image" src="images/side_by_side.png" width="700" alt="Light Transport Equation"/>
        </div>
        
        <p>
            This is definitely still an on-going project and probably always will be because there's plenty of room for new features and tweaks. Currently it can only read OBJs, which is good for still renders, but my goal is make it capable of animations. For that, it needs to be able to do transformations and vertex skinning. I could do an OBJ sequence, but that would take up a massive amount of storage since each frame has millions of vertices. My plan is to make a file converter that takes an input of a popular 3D file format (likely .fbx), and converts it into a proprietary XML file that works best for my path tracer. There's a few scene parsers out there that deal with this, but I want to build as much of it as I can to keep my code dependencies low. This way it'll be easily portable and able to run on anything from an ARM to a Linux based server. 
        </p>
        
      <div class="w3-row">
        <div class="w3-col m8 s12 w3-padding">
            <a class="w3-btn w3-padding-large w3-white w3-border w3-hover-border-black" href="../../projects.html">BACK</a>
        </div>
      </div>

    </div>
  </div>
<!-- END BLOG ENTRIES -->
</div>
<!-- END PAGE CONTENT -->
</div>    

</body>
</html>
